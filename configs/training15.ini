#training.ini Compare to 12
[default]
; random seed for torch
seed = 1234 
; number of batches parsed through before printing info
print_freq = 5
; save model every save_model_freq'th epoch
save_model_freq = 25

[hyperparameters]
; number of epochs (epochs defined as 'qsize_class' numbers of imgs from each class)
epochs = 200
; initial kl_div scale for loss function
kl_scale_init = 1e-8
; kl_div scale for loss function at last epoch (exponential growth)
kl_scale_end = 1e-3
; ratio of epochs for warming up kl_div
kl_warmup = 0.06
; determines whether margin is fixed or based on average dist to negatives
margin_fixed = True
; if margin is fixed, this is the absolute distance, otherwise multi with avg.dist
margin_val = 0
; variance of prior
var_prior = 0.1
; number of queries in one batch
batch_size = 80
; number of batches parsed throug before doing a gradient update
update_every = 1
; number of epoch before updating backbone repr. pool (also new image augmentation for train)
update_pool_every = 2
; gradient clipping val
clip = 1
; learning_rate at first epoch
lr_init = 3e-3
; learning_rate at last epoch (exponential growth)
lr_end = 3e-5
; probability of skipping closest negative when creating tuples
skip_closest_neg_prob = 0.0

[model]
; backbone architecture
architecture = 'resnet152'
; should backbone model be fixed?
fixed_backbone = True
; should backbone model be kept in eval mode?
const_eval_mode = True
; dim of mean and variance fc head
head_layers_dim = {'mean': [30], 'var': [30]}
; activation function for non-linearity
activation_fn = {'type': 'relu', 'param': None}
; GeM pooling parameter (power)
pooling = {'mGeM_p': 2,'vGeM_p': 3}
; output dim, mean: (n-1), var: 1 
dim_out = 18
; dropout perc. for fc layers
dropout = 0.50
; variance type
var_type = 'diag'

[image_transform]
; img size
img_size = 224
; augmentations of training images
augmentation = True
; normalization for imgs.
normalize = {'mean': [0.485, 0.456, 0.406],'var' : [0.229, 0.224, 0.225]}

[dataset]
; number of negatives for each query
nnum = 10
; number of queries for each class per epoch
qsize_class = 400
; number of images for each class in training pool
poolsize_class = 10000
; should we keep tuples from previous generation?
keep_prev_tuples = False
; classes not trained on
classes_not_trained_on = ['horse','car']
; TupleLoader approximative similarity measure
approx_similarity = False
; distribution of classes for negative ('uniform', 'unif_to_free', 'free')
neg_class_dist = 'uniform'